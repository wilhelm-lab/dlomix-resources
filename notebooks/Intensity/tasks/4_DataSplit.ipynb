{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retention Time Preidiction \n",
    "\n",
    "This notebook is prepared to be run in Google [Colaboratory](https://colab.research.google.com/). In order to train the model faster, please change the runtime of Colab to use Hardware Accelerator, either GPU or TPU.\n",
    "\n",
    "This is an extension of the original walkthrough example available [here](https://github.com/wilhelm-lab/dlomix-resources/blob/main/notebooks/Example_RTModel_Walkthrough_colab.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Data Split\n",
    "Similar to the initial notebook, we will initialize our model and train it. The target here is to experiment with different data splits and observe the impact on the performance and whether it reflects a realistic evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# install the mlomix package in the current environment using pip\n",
    "\n",
    "!python -m pip install -q dlomix==0.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dlomix\n",
    "from dlomix.models import RetentionTimePredictor\n",
    "import tensorflow as tf\n",
    "from dlomix.eval import TimeDeltaMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates a dataset, creates the model, and trains it. You should try with the two available data splits (`split_a` and `split_b`). Please Refer to the initial notebook to analyze the results.\n",
    "\n",
    "Hint: Use the paths available below. Description for splits is as follows:\n",
    "- suffix `_DATAPATH`: the original split used in the intial walkthrough notebook.\n",
    "- suffix `_A`: split A\n",
    "- suffix `_B`: split B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATAPATH = 'https://raw.githubusercontent.com/wilhelm-lab/dlomix-resources/main/example_datasets/RetentionTime/proteomTools_train_val.csv'\n",
    "TRAIN_DATAPATH_A = 'https://raw.githubusercontent.com/wilhelm-lab/dlomix-resources/main/example_datasets/RetentionTime/split_a/proteomTools_train_val_a.csv'\n",
    "TRAIN_DATAPATH_B = 'https://raw.githubusercontent.com/wilhelm-lab/dlomix-resources/main/example_datasets/RetentionTime/split_b/proteomTools_train_val_b.csv'\n",
    "\n",
    "TEST_DATAPATH = 'https://raw.githubusercontent.com/wilhelm-lab/dlomix-resources/main/example_datasets/RetentionTime/proteomTools_test.csv'\n",
    "TEST_DATAPATH_A = 'https://raw.githubusercontent.com/wilhelm-lab/dlomix-resources/main/example_datasets/RetentionTime/split_a/proteomTools_test_a.csv'\n",
    "TEST_DATAPATH_B = 'https://raw.githubusercontent.com/wilhelm-lab/dlomix-resources/main/example_datasets/RetentionTime/split_b/proteomTools_test_b.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlomix.data import RetentionTimeDataset\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "rtdata = RetentionTimeDataset(data_source=TRAIN_DATAPATH,\n",
    "                              seq_length=30, batch_size=BATCH_SIZE, val_ratio=0.2)\n",
    "\n",
    "\n",
    "# this is the test dataset object, do not forget to change it to the respective suffix (A or B)\n",
    "# when you change the training dataset\n",
    "\n",
    "test_rtdata = RetentionTimeDataset(data_source=TEST_DATAPATH,\n",
    "                              seq_length=30, batch_size=BATCH_SIZE, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = RetentionTimePredictor(seq_length=30)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
    "\n",
    "# compile the model  with the optimizer and the metrics we want to use, we can add our custom time-delta metric\n",
    "\n",
    "model.compile(optimizer=optimizer, \n",
    "            loss='mse', metrics=['mean_absolute_error', TimeDeltaMetric()])\n",
    "\n",
    "history = model.fit(rtdata.train_data, validation_data=rtdata.val_data, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus:\n",
    "After analyzing the results, can you figure out what is wrong with these splits and how different are they from each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
