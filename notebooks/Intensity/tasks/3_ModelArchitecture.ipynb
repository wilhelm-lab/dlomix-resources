{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fragment ion intensities Prediction \n",
    "\n",
    "This notebook is prepared to be run in Google [Colaboratory](https://colab.research.google.com/). In order to train the model faster, please change the runtime of Colab to use Hardware Accelerator, either GPU or TPU.\n",
    "\n",
    "This is an extension of the original walkthrough example available [here](https://github.com/wilhelm-lab/dlomix-resources/tree/tasks/intensity/notebooks/Intensity/Example_IntensityModel_Walkthrough_colab.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Loss Function\n",
    "Similar to the initial notebook, we will initialize our model and train it. The target here is to experiment with different loss functions and observe thg performance of the trained model. The loss function is our optimization objective, which we use to quantify how good or bad our model, being trained, is performing and find better set of parameters that result in better performance on the task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# install the mlomix package in the current environment using pip\n",
    "\n",
    "!python -m pip install -q git+https://github.com/wilhelm-lab/dlomix.git@feature/intensity_tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dlomix\n",
    "from dlomix.models import PrositIntensityPredictor\n",
    "import tensorflow as tf\n",
    "from dlomix.losses import masked_spectral_distance, masked_pearson_correlation_distance\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter project name for weights and biases\n",
    "project_name = 'dlomix_intensity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlomix.data import IntensityDataset\n",
    "\n",
    "TRAIN_DATAPATH = 'https://raw.githubusercontent.com/wilhelm-lab/dlomix-resources/main/example_datasets/Intensity/proteomeTools_train_val.csv'\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "int_data = IntensityDataset(data_source=TRAIN_DATAPATH,\n",
    "                              seq_length=30, collision_energy_col='collision_energy', batch_size=BATCH_SIZE, val_ratio=0.2, test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates a model and trains it. You should try out different loss functions and observe the impact on the training. Please Refer to the initial notebook to analyze the results.\n",
    "\n",
    "Hint: Change embedding_output_dim size and recurrent layers size and explore how this would change the model performance. The parameter embedding_dim is the size of vector representing each Amino Acid, the higher it is, the more representative power it has. The recurrent layers size is the number of units in the two GRU layers in the model encoder, the higher it is, the more parameters the model will have and that can help with detecting complex patterns but can also lead to overfitting.\n",
    "\n",
    "Change one thing at time to see how it will affect the model. Possible values are:\n",
    "\n",
    "- `embedding_output_dim`: use values from the range $1$ to $25$\n",
    "- `recurrent_layers_sizes`: use values from the range of $32$ to $512$ increment in powers of two\n",
    "\n",
    "Current values set are the default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwassimg\u001b[0m (\u001b[33mprosit-compms\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4e3c76182e43649908b275595ac306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\Compmass\\dlomix-resources\\notebooks\\Intensity\\tasks\\wandb\\run-20230225_142619-buy1rtsl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/prosit-compms/dlomix_intensity/runs/buy1rtsl' target=\"_blank\">model_arc_</a></strong> to <a href='https://wandb.ai/prosit-compms/dlomix_intensity' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/prosit-compms/dlomix_intensity' target=\"_blank\">https://wandb.ai/prosit-compms/dlomix_intensity</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/prosit-compms/dlomix_intensity/runs/buy1rtsl' target=\"_blank\">https://wandb.ai/prosit-compms/dlomix_intensity/runs/buy1rtsl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "369/369 [==============================] - 36s 69ms/step - loss: 0.6132 - masked_pearson_correlation_distance: 0.4860 - val_loss: 0.5744 - val_masked_pearson_correlation_distance: 0.4455: 4s - loss: 0.6203 - masked_pearson_correla - ETA: 3s - loss:\n",
      "Epoch 2/15\n",
      "369/369 [==============================] - 23s 62ms/step - loss: 0.5759 - masked_pearson_correlation_distance: 0.4457 - val_loss: 0.5679 - val_masked_pearson_correlation_distance: 0.4450\n",
      "Epoch 3/15\n",
      "369/369 [==============================] - 23s 62ms/step - loss: 0.5706 - masked_pearson_correlation_distance: 0.4476 - val_loss: 0.5617 - val_masked_pearson_correlation_distance: 0.4368\n",
      "Epoch 4/15\n",
      "369/369 [==============================] - 23s 63ms/step - loss: 0.5524 - masked_pearson_correlation_distance: 0.4288 - val_loss: 0.5260 - val_masked_pearson_correlation_distance: 0.3828\n",
      "Epoch 5/15\n",
      "369/369 [==============================] - 15s 39ms/step - loss: 0.5287 - masked_pearson_correlation_distance: 0.3998 - val_loss: 0.5142 - val_masked_pearson_correlation_distance: 0.3816\n",
      "Epoch 6/15\n",
      "369/369 [==============================] - 15s 40ms/step - loss: 0.5185 - masked_pearson_correlation_distance: 0.3967 - val_loss: 0.5048 - val_masked_pearson_correlation_distance: 0.3789loss: 0.5227 - masked_pearson_correl - ETA: 10s - loss: 0.5217 - masked_pearson_correlati\n",
      "Epoch 7/15\n",
      "369/369 [==============================] - 14s 39ms/step - loss: 0.5108 - masked_pearson_correlation_distance: 0.3938 - val_loss: 0.4954 - val_masked_pearson_correlation_distance: 0.3672\n",
      "Epoch 8/15\n",
      "369/369 [==============================] - 14s 37ms/step - loss: 0.5046 - masked_pearson_correlation_distance: 0.3886 - val_loss: 0.4895 - val_masked_pearson_correlation_distance: 0.3642\n",
      "Epoch 9/15\n",
      "369/369 [==============================] - 13s 37ms/step - loss: 0.4997 - masked_pearson_correlation_distance: 0.3880 - val_loss: 0.4818 - val_masked_pearson_correlation_distance: 0.3650\n",
      "Epoch 10/15\n",
      "369/369 [==============================] - 13s 37ms/step - loss: 0.4942 - masked_pearson_correlation_distance: 0.3861 - val_loss: 0.4807 - val_masked_pearson_correlation_distance: 0.3670\n",
      "Epoch 11/15\n",
      "369/369 [==============================] - 14s 38ms/step - loss: 0.4887 - masked_pearson_correlation_distance: 0.3847 - val_loss: 0.4699 - val_masked_pearson_correlation_distance: 0.3502\n",
      "Epoch 12/15\n",
      "369/369 [==============================] - 14s 37ms/step - loss: 0.4838 - masked_pearson_correlation_distance: 0.3834 - val_loss: 0.4673 - val_masked_pearson_correlation_distance: 0.3621\n",
      "Epoch 13/15\n",
      "369/369 [==============================] - 18s 50ms/step - loss: 0.4788 - masked_pearson_correlation_distance: 0.3818 - val_loss: 0.4616 - val_masked_pearson_correlation_distance: 0.3646\n",
      "Epoch 14/15\n",
      "369/369 [==============================] - 14s 37ms/step - loss: 0.4744 - masked_pearson_correlation_distance: 0.3809 - val_loss: 0.4525 - val_masked_pearson_correlation_distance: 0.3512\n",
      "Epoch 15/15\n",
      "369/369 [==============================] - 14s 38ms/step - loss: 0.4701 - masked_pearson_correlation_distance: 0.3770 - val_loss: 0.4503 - val_masked_pearson_correlation_distance: 0.3461\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef604c690f94c1cb7046759eacadd6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>loss</td><td>█▆▆▅▄▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>masked_pearson_correlation_distance</td><td>█▅▆▄▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▇▅▅▄▄▃▃▃▂▂▂▁▁</td></tr><tr><td>val_masked_pearson_correlation_distance</td><td>██▇▄▃▃▂▂▂▂▁▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>14</td></tr><tr><td>best_val_loss</td><td>0.45027</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>loss</td><td>0.4701</td></tr><tr><td>masked_pearson_correlation_distance</td><td>0.377</td></tr><tr><td>val_loss</td><td>0.45027</td></tr><tr><td>val_masked_pearson_correlation_distance</td><td>0.34612</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">model_arc_</strong> at: <a href='https://wandb.ai/prosit-compms/dlomix_intensity/runs/buy1rtsl' target=\"_blank\">https://wandb.ai/prosit-compms/dlomix_intensity/runs/buy1rtsl</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230225_142619-buy1rtsl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Enter weights and biases run name. Make sure that different models have different run names.\n",
    "wandb.init(project=project_name, name='model_arc_')\n",
    "\n",
    "# create model\n",
    "model = PrositIntensityPredictor(seq_length=30,embedding_output_dim=16,\n",
    "        recurrent_layers_sizes=(256, 512))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "# compile the model  with the optimizer and the metrics we want to use, we can add our custom time-delta metric\n",
    "\n",
    "model.compile(optimizer=optimizer, \n",
    "            loss=masked_spectral_distance, metrics=[masked_pearson_correlation_distance])\n",
    "\n",
    "history = model.fit(int_data.train_data, validation_data=int_data.val_data, epochs=30\n",
    "                    , callbacks=[WandbCallback(save_model=False)])\n",
    "\n",
    "# Mark the run as finished\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
