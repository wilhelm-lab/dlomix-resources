{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fragment ion intensities Prediction \n",
    "\n",
    "This notebook is prepared to be run in Google [Colaboratory](https://colab.research.google.com/). In order to train the model faster, please change the runtime of Colab to use Hardware Accelerator, either GPU or TPU.\n",
    "\n",
    "This is an extension of the original walkthrough example available [here](https://github.com/wilhelm-lab/dlomix-resources/tree/tasks/intensity/notebooks/Intensity/Example_IntensityModel_Walkthrough_colab.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Learning Rate\n",
    "Similar to the initial notebook, we will initialize our model and train it. The target here is to experiment with different values for the learning rate and check which learning rate would be the best to work with our task/dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# install the mlomix package in the current environment using pip\n",
    "\n",
    "!python -m pip install -q git+https://github.com/wilhelm-lab/dlomix.git@feature/intensity_tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -q wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dlomix\n",
    "from dlomix.models import PrositIntensityPredictor\n",
    "import tensorflow as tf\n",
    "from dlomix.losses import masked_spectral_distance, pearson_correlation\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter project name for weights and biases\n",
    "project_name = 'dlomix_intensity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlomix.data import IntensityDataset\n",
    "\n",
    "TRAIN_DATAPATH = 'https://raw.githubusercontent.com/wilhelm-lab/dlomix-resources/tasks/intensity/example_datasets/Intensity/proteomeTools_train_val.csv'\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "int_data = IntensityDataset(data_source=TRAIN_DATAPATH,\n",
    "                              seq_length=30, collision_energy_col='collision_energy', batch_size=BATCH_SIZE, val_ratio=0.2, test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates a model and trains it. You should try out different values for the learning rate, which is the step size we use to update the parameters of the model (weights).  Please Refer to the initial notebook to analyze the results.\n",
    "\n",
    "Hint: Explore the following range of values: $0.1$ to $10^{-6}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter weights and biases run name. Make sure that different learning rates have different run names.\n",
    "wandb.init(project=project_name, name='learning_rate')\n",
    "\n",
    "# create model\n",
    "model = PrositIntensityPredictor(seq_length=30)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
    "\n",
    "# compile the model  with the optimizer and the metrics we want to use, we can add our custom time-delta metric\n",
    "\n",
    "model.compile(optimizer=optimizer, \n",
    "            loss=masked_spectral_distance, metrics=[pearson_correlation,'mean_absolute_error', 'mse'])\n",
    "\n",
    "history = model.fit(rtdata.train_data, validation_data=rtdata.val_data, epochs=15\n",
    "                    ,callbacks=[WandbCallback(save_model=False)])\n",
    "\n",
    "\n",
    "# Mark the run as finished\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
