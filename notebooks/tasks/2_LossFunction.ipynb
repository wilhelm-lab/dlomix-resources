{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retention Time Preidiction \n",
    "\n",
    "This notebook is prepared to be run in Google [Colaboratory](https://colab.research.google.com/). In order to train the model faster, please change the runtime of Colab to use Hardware Accelerator, either GPU or TPU.\n",
    "\n",
    "This is an extension of the original walkthrough example available [here](https://github.com/wilhelm-lab/dlomix-resources/blob/main/notebooks/Example_RTModel_Walkthrough_colab.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Loss Function\n",
    "Similar to the initial notebook, we will initialize our model and train it. The target here is to experiment with different loss functions and observe thg performance of the trained model. The loss function is our optimization objective, which we use to quantify how good or bad our model, being trained, is performing and find better set of parameters that result in better performance on the task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# install the mlomix package in the current environment using pip\n",
    "\n",
    "!python -m pip install -q git+https://github.com/wilhelm-lab/dlomix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dlomix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlomix.data import RetentionTimeDataset\n",
    "\n",
    "TRAIN_DATAPATH = 'https://raw.githubusercontent.com/wilhelm-lab/dlomix/develop/example_dataset/proteomTools_train_val.csv'\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "rtdata = RetentionTimeDataset(data_source=TRAIN_DATAPATH,\n",
    "                              seq_length=30, batch_size=BATCH_SIZE, val_ratio=0.2, test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates a model and trains it. You should try out different loss functions and observe the impact on the training. Please Refer to the initial notebook to analyze the results.\n",
    "\n",
    "Hint: Explore the difference between mean squared error (`` and mean absolute error. Details about loss functions available in `tf.keras` are here: https://www.tensorflow.org/api_docs/python/tf/keras/losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = 'mse'\n",
    "\n",
    "# create model\n",
    "model = RetentionTimePredictor(seq_length=30)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4, decay=1e-7)\n",
    "\n",
    "# compile the model  with the optimizer and the metrics we want to use, we can add our custom time-delta metric\n",
    "\n",
    "model.compile(optimizer=optimizer, \n",
    "            loss=loss_function, metrics=[TimeDeltaMetric()])\n",
    "\n",
    "history = model.fit(rtdata.train_data, validation_data=rtdata.val_data, epochs=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
